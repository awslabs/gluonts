{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer callbacks\n",
    "\n",
    "This notebook illustrates how one can control the training procedure of MXNet-based models by providing callbacks to the `Trainer` class.\n",
    "A callback is a function which gets called at one or more specific hook points during training.\n",
    "You can use predefined GluonTS callbacks like `TrainingHistory`, `ModelAveraging` or `TerminateOnNaN`, or you can implement your own callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-13T08:55:29.915836Z",
     "iopub.status.busy": "2022-06-13T08:55:29.914796Z",
     "iopub.status.idle": "2022-06-13T08:55:30.872067Z",
     "shell.execute_reply": "2022-06-13T08:55:30.872732Z"
    }
   },
   "outputs": [],
   "source": [
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "\n",
    "dataset = get_dataset(\"m4_hourly\")\n",
    "prediction_length = dataset.metadata.prediction_length\n",
    "freq = dataset.metadata.freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a single callback\n",
    "\n",
    "To use callbacks, simply pass them as a list when constructing the `Trainer`:\n",
    "in the following example, we are using the `TrainingHistory` callback to record loss values measured during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-13T08:55:30.879528Z",
     "iopub.status.busy": "2022-06-13T08:55:30.878629Z",
     "iopub.status.idle": "2022-06-13T08:55:34.171888Z",
     "shell.execute_reply": "2022-06-13T08:55:34.172380Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████████████████████████████████████| 50/50 [00:00<00:00, 96.50it/s, epoch=1/3, avg_epoch_loss=5.52]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████| 50/50 [00:00<00:00, 112.73it/s, epoch=2/3, avg_epoch_loss=4.79]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████| 50/50 [00:00<00:00, 117.47it/s, epoch=3/3, avg_epoch_loss=4.75]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.mx import Trainer\n",
    "from gluonts.mx.trainer.callback import TrainingHistory\n",
    "\n",
    "# defining a callback, which will log the training loss for each epoch\n",
    "history = TrainingHistory()\n",
    "\n",
    "trainer = Trainer(epochs=3, callbacks=[history])\n",
    "estimator = SimpleFeedForwardEstimator(prediction_length=prediction_length, freq=freq, trainer=trainer)\n",
    "\n",
    "predictor = estimator.train(dataset.train, num_workers=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the training loss over the epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-13T08:55:34.176570Z",
     "iopub.status.busy": "2022-06-13T08:55:34.175723Z",
     "iopub.status.idle": "2022-06-13T08:55:34.178374Z",
     "shell.execute_reply": "2022-06-13T08:55:34.178870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.524826107025146, 4.7877399396896365, 4.753161411285401]\n"
     ]
    }
   ],
   "source": [
    "print(history.loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using multiple callbacks\n",
    "\n",
    "To continue the training from a given predictor you can use the `WarmStart` callback.\n",
    "When you want to use more than one callback, just provide a list with multiple callback objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-13T08:55:34.184349Z",
     "iopub.status.busy": "2022-06-13T08:55:34.183622Z",
     "iopub.status.idle": "2022-06-13T08:55:35.457863Z",
     "shell.execute_reply": "2022-06-13T08:55:35.458282Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████| 50/50 [00:00<00:00, 129.71it/s, epoch=1/3, avg_epoch_loss=4.47]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████| 50/50 [00:00<00:00, 114.92it/s, epoch=2/3, avg_epoch_loss=4.42]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████| 50/50 [00:00<00:00, 132.31it/s, epoch=3/3, avg_epoch_loss=4.46]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from gluonts.mx.trainer.callback import WarmStart\n",
    "\n",
    "warm_start = WarmStart(predictor=predictor)\n",
    "\n",
    "trainer=Trainer(epochs=3, callbacks=[history, warm_start])\n",
    "\n",
    "estimator = SimpleFeedForwardEstimator(prediction_length=prediction_length, freq=freq, trainer=trainer)\n",
    "\n",
    "predictor = estimator.train(dataset.train, num_workers=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-13T08:55:35.462380Z",
     "iopub.status.busy": "2022-06-13T08:55:35.461363Z",
     "iopub.status.idle": "2022-06-13T08:55:35.464052Z",
     "shell.execute_reply": "2022-06-13T08:55:35.464465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.524826107025146, 4.7877399396896365, 4.753161411285401, 4.465624120235443, 4.42056410074234, 4.463750073909759]\n"
     ]
    }
   ],
   "source": [
    "print(history.loss_history) # The training loss history of all 3+3 epochs we trained the model for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default callbacks\n",
    "\n",
    "In addition to the callbacks you specify, the `Trainer` class uses the two default callbacks `ModelAveraging` and `LearningRateReduction`.\n",
    "You can turn them off by setting `add_default_callbacks=False` when initializing the Trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-13T08:55:35.469342Z",
     "iopub.status.busy": "2022-06-13T08:55:35.468319Z",
     "iopub.status.idle": "2022-06-13T08:55:35.470676Z",
     "shell.execute_reply": "2022-06-13T08:55:35.471087Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer=Trainer(epochs=20, callbacks=[history]) # use the TrainingHistory Callback and the default callbacks.\n",
    "trainer=Trainer(epochs=20, callbacks=[history], add_default_callbacks=False) # use only the TrainingHistory Callback\n",
    "trainer=Trainer(epochs=20, add_default_callbacks=False) # use no callback at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom callbacks\n",
    "\n",
    "To implement your own callback you can write a class which inherits from `gluonts.mx.trainer.Callback`, and overwrite one or more of the hooks.\n",
    "Have a look at the abstract `Callback` class, the hooks take different arguments which you can use. \n",
    "Hook methods with boolean return value stop the training if False is returned.\n",
    "\n",
    "Here is an example for a custom callback implementation which terminates training early based on the value of some metric (such as the RMSE).\n",
    "It only implements the hook method `on_epoch_end` which gets called after all batches of one epoch have been processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-13T08:55:35.483476Z",
     "iopub.status.busy": "2022-06-13T08:55:35.473382Z",
     "iopub.status.idle": "2022-06-13T08:55:35.490548Z",
     "shell.execute_reply": "2022-06-13T08:55:35.491009Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "\n",
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.dataset.common import Dataset\n",
    "from gluonts.mx import copy_parameters, GluonPredictor\n",
    "from gluonts.mx.trainer.callback import Callback\n",
    "\n",
    "\n",
    "class MetricInferenceEarlyStopping(Callback):\n",
    "    \"\"\"\n",
    "    Early Stopping mechanism based on the prediction network.\n",
    "    Can be used to base the Early Stopping directly on a metric of interest, instead of on the training/validation loss.\n",
    "    In the same way as test datasets are used during model evaluation,\n",
    "    the time series of the validation_dataset can overlap with the train dataset time series,\n",
    "    except for a prediction_length part at the end of each time series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    validation_dataset\n",
    "        An out-of-sample dataset which is used to monitor metrics\n",
    "    predictor\n",
    "        A gluon predictor, with a prediction network that matches the training network\n",
    "    evaluator\n",
    "        The Evaluator used to calculate the validation metrics.\n",
    "    metric\n",
    "        The metric on which to base the early stopping on.\n",
    "    patience\n",
    "        Number of epochs to train on given the metric did not improve more than min_delta.\n",
    "    min_delta\n",
    "        Minimum change in the monitored metric counting as an improvement\n",
    "    verbose\n",
    "        Controls, if the validation metric is printed after each epoch.\n",
    "    minimize_metric\n",
    "        The metric objective.\n",
    "    restore_best_network\n",
    "        Controls, if the best model, as assessed by the validation metrics is restored after training.\n",
    "    num_samples\n",
    "        The amount of samples drawn to calculate the inference metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        validation_dataset: Dataset,\n",
    "        predictor: GluonPredictor,\n",
    "        evaluator: Evaluator = Evaluator(num_workers=None),\n",
    "        metric: str = \"MSE\",\n",
    "        patience: int = 10,\n",
    "        min_delta: float = 0.0,\n",
    "        verbose: bool = True,\n",
    "        minimize_metric: bool = True,\n",
    "        restore_best_network: bool = True,\n",
    "        num_samples: int = 100,\n",
    "    ):\n",
    "        assert (\n",
    "            patience >= 0\n",
    "        ), \"EarlyStopping Callback patience needs to be >= 0\"\n",
    "        assert (\n",
    "            min_delta >= 0\n",
    "        ), \"EarlyStopping Callback min_delta needs to be >= 0.0\"\n",
    "        assert (\n",
    "            num_samples >= 1\n",
    "        ), \"EarlyStopping Callback num_samples needs to be >= 1\"\n",
    "\n",
    "        self.validation_dataset = list(validation_dataset)\n",
    "        self.predictor = predictor\n",
    "        self.evaluator = evaluator\n",
    "        self.metric = metric\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.restore_best_network = restore_best_network\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "        if minimize_metric:\n",
    "            self.best_metric_value = np.inf\n",
    "            self.is_better = np.less\n",
    "        else:\n",
    "            self.best_metric_value = -np.inf\n",
    "            self.is_better = np.greater\n",
    "\n",
    "        self.validation_metric_history: List[float] = []\n",
    "        self.best_network = None\n",
    "        self.n_stale_epochs = 0\n",
    "\n",
    "    def on_epoch_end(\n",
    "        self,\n",
    "        epoch_no: int,\n",
    "        epoch_loss: float,\n",
    "        training_network: mx.gluon.nn.HybridBlock,\n",
    "        trainer: mx.gluon.Trainer,\n",
    "        best_epoch_info: dict,\n",
    "        ctx: mx.Context\n",
    "    ) -> bool:\n",
    "        should_continue = True\n",
    "        copy_parameters(training_network, self.predictor.prediction_net)\n",
    "\n",
    "        from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "\n",
    "        forecast_it, ts_it = make_evaluation_predictions(\n",
    "            dataset=self.validation_dataset,\n",
    "            predictor=self.predictor,\n",
    "            num_samples=self.num_samples,\n",
    "        )\n",
    "\n",
    "        agg_metrics, item_metrics = self.evaluator(ts_it, forecast_it)\n",
    "        current_metric_value = agg_metrics[self.metric]\n",
    "        self.validation_metric_history.append(current_metric_value)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f\"Validation metric {self.metric}: {current_metric_value}, best: {self.best_metric_value}\"\n",
    "            )\n",
    "\n",
    "        if self.is_better(current_metric_value, self.best_metric_value):\n",
    "            self.best_metric_value = current_metric_value\n",
    "\n",
    "            if self.restore_best_network:\n",
    "                training_network.save_parameters(\"best_network.params\")\n",
    "\n",
    "            self.n_stale_epochs = 0\n",
    "        else:\n",
    "            self.n_stale_epochs += 1\n",
    "            if self.n_stale_epochs == self.patience:\n",
    "                should_continue = False\n",
    "                print(\n",
    "                    f\"EarlyStopping callback initiated stop of training at epoch {epoch_no}.\"\n",
    "                )\n",
    "\n",
    "                if self.restore_best_network:\n",
    "                    print(\n",
    "                        f\"Restoring best network from epoch {epoch_no - self.patience}.\"\n",
    "                    )\n",
    "                    training_network.load_parameters(\"best_network.params\")\n",
    "\n",
    "        return should_continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the custom callback as follows.\n",
    "Note that we're running an extremely short number of epochs, simply to keep the runtime of the notebook manageable:\n",
    "feel free to increase the number of epochs to properly test the effectiveness of the callback.\n",
    "\n",
    "```python\n",
    "estimator = SimpleFeedForwardEstimator(prediction_length=prediction_length, freq=freq)\n",
    "training_network = estimator.create_training_network()\n",
    "transformation = estimator.create_transformation()\n",
    "\n",
    "predictor = estimator.create_predictor(transformation=transformation, trained_network=training_network)\n",
    "\n",
    "es_callback = MetricInferenceEarlyStopping(validation_dataset=dataset.test, predictor=predictor, metric=\"MSE\")\n",
    "\n",
    "trainer = Trainer(epochs=5, callbacks=[es_callback])\n",
    "\n",
    "estimator.trainer = trainer\n",
    "\n",
    "pred = estimator.train(dataset.train)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}