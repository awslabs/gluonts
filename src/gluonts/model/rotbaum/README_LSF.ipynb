{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "destroyed-hamburg",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This document concerns how to use the GluonTS implementation of [Level Set Forecaster](https://papers.nips.cc/paper/2021/hash/32b127307a606effdcc8e51f60a45922-Abstract.html). Level Set Forecaster (LSF) is an algorithm for a tabular point prediction algorithm into a probabilistic one.\n",
    "\n",
    "A tabular point prediction algorithm is an algorithm that takes in tabular data and, at inference, outputs real numbers. Examples include: linear regression, random forests, XGBoost, etc. A tabular probabilistic prediction algorithm is one that at inference outputs an estimate of the conditional distribution.\n",
    "\n",
    "The high-level description of the LSF algorithm is that it bins the training data in such a manner that the predictions of the feature vectors in each bin are similar. At inference, it then uses the empirical distribution of true values for the bin associated with the new feature vector. We invite those who are interested to read the details and the theoretical guarantees in the [NeurIPS paper](https://papers.nips.cc/paper/2021/hash/32b127307a606effdcc8e51f60a45922-Abstract.html). \n",
    "\n",
    "The better your underlying model, the better performing its LSF wrapping will be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-cylinder",
   "metadata": {},
   "source": [
    "# Retrofitting an Existing Model\n",
    "\n",
    "Assume that you have trained a tabular point prediction algorithm and named it `underlying_model`. In order to wrap it with LSF, you have to feed into LSF the a dataset from the same distribution that `underlying_model` was trained on:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-union",
   "metadata": {},
   "source": [
    "```\n",
    "from gluonts.model.rotbaum._model import LSF\n",
    "model = LSF(model=underlying_model)\n",
    "model.fit(X_train, y_train, model_is_already_trained=True, min_bin_size=100)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-constraint",
   "metadata": {},
   "source": [
    "It is possible to provide LSF the exact same dataset that `underlying_model` was trained on, but it is necessary. There is also no assumption that the dataset provided to LSF is the same size as the one provided to `underlying_model`.\n",
    "\n",
    "The hyperparameter `min_bin_size` is by default `100`. While the NeurIPS paper ensures consistency, under certain conditions, with an increasing `min_bin_size` (of order of magnitude `(ln(n))^2`), in practice we have found that keeping this hyperparameter at `100` works in a surprisingly wide variety of datasets.\n",
    "\n",
    "Note that some `underlying_model`s assume that `X_train` is a list of lists (or numpy array of numpy arrays), whereas some assume that it is a pandas dataframe. By default LSF works with the former. To apply LSF to the latter, simply set `x_train_is_dataframe=True` in `model.fit`.\n",
    "\n",
    "Note that while LSF is native to the tabular use case, it is possible to apply it with neural networks as well. To that end, LSF can come in at the embedding level of the architecture. To be a little more explicit, if f1 is the portion of the neural network that embeds the data into a fixed dimensional space, and the remainder of the network is f2, then after training you would cache pairs of embeddings and true target values, and later feed them into LSF together with f2 as the base algorithm. At inference, rather than feeding in the raw data, you would feed the data into f1 to obtain a fixed length feature vector, and only then feed it into the LSF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-musical",
   "metadata": {},
   "source": [
    "# Letting LSF Train the Tabular Model As Well\n",
    "\n",
    "Letting `model_is_already_trained=False` (as is the default), LSF will train `underlying_model` first and only then wrap it with LSF.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-guest",
   "metadata": {},
   "source": [
    "```\n",
    "from gluonts.model.rotbaum._model import LSF\n",
    "from xgboost import XGBModel\n",
    "underlying_model = XGBModel(\n",
    "         base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "         colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "         importance_type='gain', interaction_constraints='',\n",
    "         learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
    "         min_child_weight=1, monotone_constraints='()',\n",
    "         n_estimators=50, n_jobs=-1, num_parallel_tree=1,\n",
    "         objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
    "         reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
    "         validate_parameters=1, verbosity=1)\n",
    "model = LSF(model=underlying_model)\n",
    "model.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-plaza",
   "metadata": {},
   "source": [
    "In case you want LSF to use less data to create the bins than the `underyling_model` uses to train, simply set `max_sample_size`. LSF will then sample `min(max_sample_size, len(X_train)` many data points from the training data without replacement for the purpose of creating the bins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-adventure",
   "metadata": {},
   "source": [
    "# LSF Wrapping XGBoost\n",
    "\n",
    "By default, without specifying an `underlying_model`, LSF will wrap XGBoost with some default parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-politics",
   "metadata": {},
   "source": [
    "```\n",
    "from gluonts.model.rotbaum._model import LSF\n",
    "model.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-still",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "If we want to estimate the conditional quantile for a specific quantile (between 0 and 1), simply query it thusly:\n",
    "```\n",
    "model.predict(X_test, quantile)\n",
    "```\n",
    "\n",
    "One can also retrieve the bin in its entirety, which in turn can be interpreted as an estimated sampling from the conditional distribution. To be precise `model.estimate_dist(X_test)` will output, in pseudocode, `[list of true values whose associated feature vectors are in the same bin as x for x in X_test]`.\n",
    "\n",
    "One can then plot histograms of the estimated conditional distributions:\n",
    "```\n",
    "from matplotlib import pyplot as plt\n",
    "plt.hist(model.estimate_dist(X_test)[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-universe",
   "metadata": {},
   "source": [
    "# Quick Synthetic Example to Get You Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complete-tournament",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hashilaf/repos/gluonts-lightgbmfork2/gluon-ts/src/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from gluonts.model.rotbaum._model import LSF\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "active-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_quantile_loss(true, pred, quantile):\n",
    "    denom = sum(np.abs(true))\n",
    "    num = sum([(1-quantile) * abs(y_hat-y) if y_hat > y\n",
    "               else quantile * abs(y_hat-y) for y_hat, y in zip(pred, true)])\n",
    "    if denom != 0:\n",
    "        return 2 * num / denom\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "passing-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [[np.random.normal(0, 1), np.random.normal(0, 1)] for i in range(10000)]\n",
    "y_train = [i + j\n",
    "           + np.random.normal(0, abs(i + j)) \n",
    "           for i, j in X_train]\n",
    "X_test = [[np.random.normal(0, 1), np.random.normal(0, 1)] for i in range(10000)]\n",
    "y_test = [i + j\n",
    "           + np.random.normal(0, abs(i + j)) \n",
    "           for i, j in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "computational-miami",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "underlying_model = LinearRegression()\n",
    "underlying_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "advanced-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSF(model=underlying_model, min_bin_size=100)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "removable-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "P10 = model.predict(X_test, 0.1)\n",
    "P50 = model.predict(X_test, 0.5)\n",
    "P90 = model.predict(X_test, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "naked-ethnic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3081968823690515\n",
      "0.6930824833526957\n",
      "0.3011483413017813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  2.,  7., 14., 13., 15., 22.,  9.,  9.,  9.]),\n",
       " array([-1.55548053, -1.12740142, -0.69932231, -0.2712432 ,  0.15683591,\n",
       "         0.58491502,  1.01299413,  1.44107324,  1.86915235,  2.29723146,\n",
       "         2.72531057]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(weighted_quantile_loss(y_test, P10, 0.1))\n",
    "print(weighted_quantile_loss(y_test, P50, 0.5))\n",
    "print(weighted_quantile_loss(y_test, P90, 0.9))\n",
    "plt.hist(model.estimate_dist([[0.5, 0.5]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-alliance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bestenv",
   "language": "python",
   "name": "bestenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
