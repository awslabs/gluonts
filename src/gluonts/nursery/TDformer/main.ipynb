{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *  # embedding layers, normalization layer\n",
    "from data import *  # data loader\n",
    "from utils import *\n",
    "from exp import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-domain attention\n",
    "\n",
    "Denote input queries, keys and values as $\\mathbf{q} \\in \\mathbb{R}^{L \\times D}, \\mathbf{k} \\in \\mathbb{R}^{L \\times D}, \\mathbf{v} \\in \\mathbb{R}^{L \\times D}$, which are transformed from input $\\mathbf{x}$ through linear embeddings. Denote output of attention module as $\\mathbf{o} ( \\mathbf{q}, \\mathbf{k}, \\mathbf{v} ) \\in \\mathbb{R}^{L \\times D}$. Time-domain attention calculates attention in the original time domain as follows:\n",
    "\n",
    "$$\\mathbf{o} ( \\mathbf{q}, \\mathbf{k}, \\mathbf{v} ) = \\sigma \\left(\\frac{\\mathbf{q}\\mathbf{k}^T}{\\sqrt{d_q}}\\right)\\mathbf{v}$$\n",
    "\n",
    "where $d_q$ is the dimension for queries that serves as normalization term in attention operation, and $\\sigma(\\cdot)$ represents activation function. When  $\\sigma(\\cdot)=\\mathrm{softmax}(\\cdot)$ ($\\mathrm{softmax}(\\mathbf{x}) = \\frac{e^{x_i}}{\\sum_i e^{x_i}}$), we have softmax attention: $\\mathbf{o} ( \\mathbf{q}, \\mathbf{k}, \\mathbf{v} ) = \\mathrm{softmax} \\left({\\mathbf{q}\\mathbf{k}^T}/{\\sqrt{d_q}}\\right)\\mathbf{v}$. When $\\sigma(\\cdot)=\\mathrm{Id}(\\cdot)$ (identity mapping), we have linear attention: $\\mathbf{o}( \\mathbf{q}, \\mathbf{k}, \\mathbf{v} ) = \\left(\\mathbf{q}\\mathbf{k}^T/\\sqrt{d_q}\\right)\\mathbf{v}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import os\n",
    "\n",
    "\n",
    "class TriangularCausalMask:\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(\n",
    "                torch.ones(mask_shape, dtype=torch.bool), diagonal=1\n",
    "            ).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "\n",
    "\n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mask_flag=True,\n",
    "        factor=3,\n",
    "        scale=None,\n",
    "        attention_dropout=0.1,\n",
    "        T=1,\n",
    "        activation=\"softmax\",\n",
    "        output_attention=False,\n",
    "    ):\n",
    "        super(FullAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.activation = activation\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "        self.T = T\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1.0 / sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys) * scale\n",
    "\n",
    "        if self.activation == \"softmax\":\n",
    "            if self.mask_flag:\n",
    "                if attn_mask is None:\n",
    "                    attn_mask = TriangularCausalMask(\n",
    "                        B, L, device=queries.device\n",
    "                    )\n",
    "\n",
    "                scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "            A = self.dropout(torch.softmax(scores / self.T, dim=-1))\n",
    "            V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        elif self.activation == \"linear\":\n",
    "            V = torch.einsum(\"bhls,bshd->blhd\", scores, values)\n",
    "\n",
    "        elif self.activation == \"linear_norm\":\n",
    "            mins = (\n",
    "                scores.min(dim=-1)[0]\n",
    "                .unsqueeze(-1)\n",
    "                .expand(-1, -1, -1, scores.shape[3])\n",
    "            )\n",
    "            scores = scores - mins + 1e-8\n",
    "\n",
    "            if self.mask_flag:\n",
    "                if attn_mask is None:\n",
    "                    attn_mask = TriangularCausalMask(\n",
    "                        B, L, device=queries.device\n",
    "                    )\n",
    "                scores.masked_fill_(attn_mask.mask, 0)\n",
    "\n",
    "            sums = (\n",
    "                scores.sum(dim=-1)\n",
    "                .unsqueeze(-1)\n",
    "                .expand(-1, -1, -1, scores.shape[3])\n",
    "            )\n",
    "            scores /= sums\n",
    "            V = torch.einsum(\"bhls,bshd->blhd\", scores, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return (V.contiguous(), A)\n",
    "        else:\n",
    "            return (V.contiguous(), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier-domain attention\n",
    "\n",
    "Fourier attention first converts queries, keys, and values with Fourier Transform, performs a similar attention mechanism in the frequency domain, and finally converts the results back to the time domain using inverse Fourier transform. Let $\\mathcal{F}(\\cdot), \\mathcal{F}^{-1}(\\cdot)$ denote Fourier transform and inverse Fourier transform, then Fourier attention is $\\mathbf{o} ( \\mathbf{q}, \\mathbf{k}, \\mathbf{v} ) = \\mathcal{F}^{-1} \\Big(\\sigma\\big({\\mathcal{F}(\\mathbf{q})\\overline{\\mathcal{F}(\\mathbf{k}}})^T/{\\sqrt{d_q}}\\big)\\mathcal{F}(\\mathbf{v})\\Big)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierAttention(nn.Module):\n",
    "    def __init__(self, T=1, activation=\"softmax\", output_attention=False):\n",
    "        super(FourierAttention, self).__init__()\n",
    "        print(\" fourier enhanced cross attention used!\")\n",
    "        \"\"\"\n",
    "        1D Fourier Cross Attention layer. It does FFT, linear transform, attention mechanism and Inverse FFT.    \n",
    "        \"\"\"\n",
    "        self.activation = activation\n",
    "        self.output_attention = output_attention\n",
    "        self.T = T\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        # size = [B, L, H, E]\n",
    "        B, L, H, E = q.shape\n",
    "        _, S, H, E = k.shape\n",
    "        xq = q.permute(0, 2, 3, 1)  # size = [B, H, E, L]\n",
    "        xk = k.permute(0, 2, 3, 1)\n",
    "        xv = v.permute(0, 2, 3, 1)\n",
    "\n",
    "        xq_ft_ = torch.fft.rfft(xq, dim=-1, norm=\"ortho\")\n",
    "        xk_ft_ = torch.fft.rfft(xk, dim=-1, norm=\"ortho\")\n",
    "        xv_ft_ = torch.fft.rfft(xv, dim=-1, norm=\"ortho\")\n",
    "\n",
    "        xqk_ft = torch.einsum(\n",
    "            \"bhex,bhey->bhxy\", xq_ft_, torch.conj(xk_ft_)\n",
    "        ) / sqrt(E)\n",
    "\n",
    "        if self.activation == \"softmax\":\n",
    "            xqk_ft = torch.softmax(xqk_ft.abs() / self.T, dim=-1)\n",
    "            xqk_ft = torch.complex(xqk_ft, torch.zeros_like(xqk_ft))\n",
    "            xqkv_ft = torch.einsum(\"bhxy,bhey->bhex\", xqk_ft, xv_ft_)\n",
    "\n",
    "        elif self.activation == \"linear\":\n",
    "            xqkv_ft = torch.einsum(\"bhxy,bhey->bhex\", xqk_ft, xv_ft_)\n",
    "\n",
    "        elif self.activation == \"linear_norm\":\n",
    "            mins_real = (\n",
    "                xqk_ft.real.min(dim=-1)[0]\n",
    "                .unsqueeze(-1)\n",
    "                .expand(-1, -1, -1, xqk_ft.shape[3])\n",
    "            )\n",
    "            xqk_ft_real = xqk_ft.real - mins_real\n",
    "            sums_real = (\n",
    "                xqk_ft_real.sum(dim=-1)\n",
    "                .unsqueeze(-1)\n",
    "                .expand(-1, -1, -1, xqk_ft.shape[3])\n",
    "            )\n",
    "            xqk_ft_real /= sums_real\n",
    "\n",
    "            mins_imag = (\n",
    "                xqk_ft.imag.min(dim=-1)[0]\n",
    "                .unsqueeze(-1)\n",
    "                .expand(-1, -1, -1, xqk_ft.shape[3])\n",
    "            )\n",
    "            xqk_ft_imag = xqk_ft.imag - mins_imag\n",
    "            sums_imag = (\n",
    "                xqk_ft_imag.sum(dim=-1)\n",
    "                .unsqueeze(-1)\n",
    "                .expand(-1, -1, -1, xqk_ft.shape[3])\n",
    "            )\n",
    "            xqk_ft_imag /= sums_imag\n",
    "\n",
    "            xqkv_ft_real = torch.einsum(\n",
    "                \"bhxy,bhey->bhex\", xqk_ft_real, xv_ft_.real\n",
    "            )\n",
    "            xqkv_ft_imag = torch.einsum(\n",
    "                \"bhxy,bhey->bhex\", xqk_ft_imag, xv_ft_.imag\n",
    "            )\n",
    "            xqkv_ft = torch.complex(xqkv_ft_real, xqkv_ft_imag)\n",
    "\n",
    "        elif self.activation == \"linear_norm_abs\":\n",
    "            xqk_ft = xqk_ft.abs() / xqk_ft.abs().sum(dim=-1).unsqueeze(\n",
    "                -1\n",
    "            ).expand(-1, -1, -1, xqk_ft.shape[3])\n",
    "            xqk_ft = torch.complex(xqk_ft, torch.zeros_like(xqk_ft))\n",
    "            xqkv_ft = torch.einsum(\"bhxy,bhey->bhex\", xqk_ft, xv_ft_)\n",
    "\n",
    "        elif self.activation == \"linear_norm_real\":\n",
    "            mins_real = (\n",
    "                xqk_ft.real.min(dim=-1)[0]\n",
    "                .unsqueeze(-1)\n",
    "                .expand(-1, -1, -1, xqk_ft.shape[3])\n",
    "            )\n",
    "            xqk_ft_real = xqk_ft.real - mins_real\n",
    "            sums_real = (\n",
    "                xqk_ft_real.sum(dim=-1)\n",
    "                .unsqueeze(-1)\n",
    "                .expand(-1, -1, -1, xqk_ft.shape[3])\n",
    "            )\n",
    "            xqk_ft_real /= sums_real\n",
    "\n",
    "            xqk_ft = torch.complex(xqk_ft_real, torch.zeros_like(xqk_ft_real))\n",
    "            xqkv_ft = torch.einsum(\"bhxy,bhey->bhex\", xqk_ft, xv_ft_)\n",
    "\n",
    "        out = torch.fft.irfft(xqkv_ft, n=L, dim=-1, norm=\"ortho\").permute(\n",
    "            0, 3, 1, 2\n",
    "        )\n",
    "\n",
    "        if self.output_attention == False:\n",
    "            return (out, None)\n",
    "        else:\n",
    "            return (out, (xqk_ft_real, xqk_ft_imag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet-domain attention\n",
    "\n",
    "Wavelet transform applies wavelet decomposition and reconstruction to obtain signals of different scales. Wavelet attention performs attention calculation to decomposed queries, keys, and values in each scale, and reconstructs the output from attention results in each scale. Let $\\mathcal{W}(\\cdot), \\mathcal{W}^{-1}(\\cdot)$ denote wavelet decomposition and wavelet reconstruction, then wavelet attention is $\\mathbf{o} ( \\mathbf{q}, \\mathbf{k}, \\mathbf{v} ) = \\mathcal{W}^{-1}\\Big(\\sigma\\left({\\mathcal{W}(\\mathbf{q})\\mathcal{W}(\\mathbf{k}^T})/{\\sqrt{d_q}}\\right)\\mathcal{W}(\\mathbf{v})\\Big)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparseKernel1d(nn.Module):\n",
    "    def __init__(self, k, c=1, nl=1, initializer=None, **kwargs):\n",
    "        super(sparseKernel1d, self).__init__()\n",
    "\n",
    "        self.k = k\n",
    "        self.Li = nn.Linear(c * k, 128)\n",
    "        self.conv = self.convBlock(c * k, 128)\n",
    "        self.Lo = nn.Linear(128, c * k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, c, ich = x.shape  # (B, N, c, k)\n",
    "        x = x.view(B, N, -1)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.Lo(x)\n",
    "        x = x.view(B, N, c, ich)\n",
    "        return x\n",
    "\n",
    "    def convBlock(self, ich, och):\n",
    "        net = nn.Sequential(\n",
    "            nn.Conv1d(ich, och, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        return net\n",
    "\n",
    "\n",
    "class WaveletAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        seq_len_q,\n",
    "        seq_len_kv,\n",
    "        c=64,\n",
    "        k=8,\n",
    "        ich=512,\n",
    "        L=3,\n",
    "        base=\"legendre\",\n",
    "        initializer=None,\n",
    "        T=1,\n",
    "        activation=\"softmax\",\n",
    "        output_attention=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(WaveletAttention, self).__init__()\n",
    "        print(\"base\", base)\n",
    "\n",
    "        self.c = c\n",
    "        self.k = k\n",
    "        self.L = L\n",
    "        self.T = T\n",
    "        self.activation = activation\n",
    "        H0, H1, G0, G1, PHI0, PHI1 = get_filter(base, k)\n",
    "        H0r = H0 @ PHI0\n",
    "        G0r = G0 @ PHI0\n",
    "        H1r = H1 @ PHI1\n",
    "        G1r = G1 @ PHI1\n",
    "\n",
    "        H0r[np.abs(H0r) < 1e-8] = 0\n",
    "        H1r[np.abs(H1r) < 1e-8] = 0\n",
    "        G0r[np.abs(G0r) < 1e-8] = 0\n",
    "        G1r[np.abs(G1r) < 1e-8] = 0\n",
    "        self.max_item = 3\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"ec_s\", torch.Tensor(np.concatenate((H0.T, H1.T), axis=0))\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"ec_d\", torch.Tensor(np.concatenate((G0.T, G1.T), axis=0))\n",
    "        )\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"rc_e\", torch.Tensor(np.concatenate((H0r, G0r), axis=0))\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"rc_o\", torch.Tensor(np.concatenate((H1r, G1r), axis=0))\n",
    "        )\n",
    "\n",
    "        self.Lk = nn.Linear(ich, c * k)\n",
    "        self.Lq = nn.Linear(ich, c * k)\n",
    "        self.Lv = nn.Linear(ich, c * k)\n",
    "        self.out = nn.Linear(c * k, ich)\n",
    "\n",
    "        self.output_attention = output_attention\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        B, N, H, E = q.shape  # (B, N, H, E) torch.Size([3, 768, 8, 2])\n",
    "        _, S, _, _ = k.shape  # (B, S, H, E) torch.Size([3, 96, 8, 2])\n",
    "\n",
    "        q = q.view(q.shape[0], q.shape[1], -1)  # (B, N, H*E)\n",
    "        k = k.view(k.shape[0], k.shape[1], -1)\n",
    "        v = v.view(v.shape[0], v.shape[1], -1)\n",
    "        q = self.Lq(q)\n",
    "        q = q.view(q.shape[0], q.shape[1], self.c, self.k)  # (B, N, E, H)\n",
    "        k = self.Lk(k)\n",
    "        k = k.view(k.shape[0], k.shape[1], self.c, self.k)\n",
    "        v = self.Lv(v)\n",
    "        v = v.view(v.shape[0], v.shape[1], self.c, self.k)\n",
    "\n",
    "        if N > S:\n",
    "            zeros = torch.zeros_like(q[:, : (N - S), :]).float()\n",
    "            v = torch.cat([v, zeros], dim=1)\n",
    "            k = torch.cat([k, zeros], dim=1)\n",
    "        else:\n",
    "            v = v[:, :N, :, :]\n",
    "            k = k[:, :N, :, :]\n",
    "        ns = math.floor(np.log2(N))\n",
    "        nl = pow(2, math.ceil(np.log2(N)))\n",
    "        extra_q = q[:, 0 : nl - N, :, :]\n",
    "        extra_k = k[:, 0 : nl - N, :, :]\n",
    "        extra_v = v[:, 0 : nl - N, :, :]\n",
    "        q = torch.cat([q, extra_q], 1)\n",
    "        k = torch.cat([k, extra_k], 1)\n",
    "        v = torch.cat([v, extra_v], 1)\n",
    "\n",
    "        Ud = torch.jit.annotate(List[Tensor], [])\n",
    "        Us = torch.jit.annotate(List[Tensor], [])\n",
    "\n",
    "        attn_d_list, attn_s_list = [], []\n",
    "\n",
    "        for i in range(ns - self.L):\n",
    "            dq, q = self.wavelet_transform(q)\n",
    "            dk, k = self.wavelet_transform(k)\n",
    "            dv, v = self.wavelet_transform(v)  # (B, N, E, H)\n",
    "\n",
    "            scores_d = torch.einsum(\"bxeh,byeh->bhxy\", dq, dk) / sqrt(E)\n",
    "\n",
    "            if self.activation == \"softmax\":\n",
    "                attn_d = F.softmax(scores_d / self.T, dim=-1)  # (B,H,q,k)\n",
    "            elif self.activation == \"linear\":\n",
    "                attn_d = scores_d  # (B,H,q,k)\n",
    "            elif self.activation == \"linear_norm\":\n",
    "                attn_d = scores_d  # (B,H,q,k)\n",
    "                mins = (\n",
    "                    attn_d.min(dim=-1)\n",
    "                    .unsqueeze(-1)\n",
    "                    .expand(-1, -1, -1, attn_d.shape[3])\n",
    "                )\n",
    "                attn_d -= mins\n",
    "                sums = (\n",
    "                    attn_d.sum(dim=-1)\n",
    "                    .unsqueeze(-1)\n",
    "                    .expand(-1, -1, -1, attn_d.shape[3])\n",
    "                )\n",
    "                attn_d /= sums\n",
    "            Ud += [torch.einsum(\"bhxy,byeh->bxeh\", attn_d, dv)]\n",
    "            attn_d_list.append(attn_d)\n",
    "\n",
    "            scores_s = torch.einsum(\"bxeh,byeh->bhxy\", q, k) / sqrt(E)\n",
    "\n",
    "            if self.activation == \"softmax\":\n",
    "                attn_s = F.softmax(scores_s / self.T, dim=-1)  # (B,H,q,k)\n",
    "            elif self.activation == \"linear\":\n",
    "                attn_s = scores_s  # (B,H,q,k)\n",
    "            elif self.activation == \"linear_norm\":\n",
    "                attn_s = scores_s  # (B,H,q,k)\n",
    "                mins = (\n",
    "                    attn_s.min(dim=-1)\n",
    "                    .unsqueeze(-1)\n",
    "                    .expand(-1, -1, -1, attn_s.shape[3])\n",
    "                )\n",
    "                attn_s -= mins\n",
    "                sums = (\n",
    "                    attn_s.sum(dim=-1)\n",
    "                    .unsqueeze(-1)\n",
    "                    .expand(-1, -1, -1, attn_s.shape[3])\n",
    "                )\n",
    "                attn_s /= sums\n",
    "            Us += [torch.einsum(\"bhxy,byeh->bxeh\", attn_s, v)]\n",
    "            attn_s_list.append(attn_s)\n",
    "\n",
    "        # reconstruct\n",
    "        for i in range(ns - 1 - self.L, -1, -1):\n",
    "            v = v + Us[i]\n",
    "            v = torch.cat((v, Ud[i]), -1)\n",
    "            v = self.evenOdd(v)\n",
    "        v = self.out(v[:, :N, :, :].contiguous().view(B, N, -1))\n",
    "        if self.output_attention == False:\n",
    "            return (v.contiguous(), None)\n",
    "        else:\n",
    "            return (v.contiguous(), (attn_s_list, attn_d_list))\n",
    "\n",
    "    def wavelet_transform(self, x):\n",
    "        xa = torch.cat(\n",
    "            [\n",
    "                x[:, ::2, :, :],\n",
    "                x[:, 1::2, :, :],\n",
    "            ],\n",
    "            -1,\n",
    "        )\n",
    "        d = torch.matmul(xa, self.ec_d)\n",
    "        s = torch.matmul(xa, self.ec_s)\n",
    "        return d, s\n",
    "\n",
    "    def evenOdd(self, x):\n",
    "        B, N, c, ich = x.shape  # (B, N, c, k)\n",
    "        assert ich == 2 * self.k\n",
    "        x_e = torch.matmul(x, self.rc_e)\n",
    "        x_o = torch.matmul(x, self.rc_o)\n",
    "\n",
    "        x = torch.zeros(B, N * 2, c, self.k, device=x.device)\n",
    "        x[..., ::2, :, :] = x_e\n",
    "        x[..., 1::2, :, :] = x_o\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer\n",
    "\n",
    "The vanilla Transformer, can specify which attention to use (time, Fourier, wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Vanilla Transformer with O(L^2) complexity\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.output_attention = configs.output_attention\n",
    "        self.enc_embedding = DataEmbedding(\n",
    "            configs.enc_in,\n",
    "            configs.d_model,\n",
    "            configs.embed,\n",
    "            configs.freq,\n",
    "            configs.dropout,\n",
    "        )\n",
    "        self.dec_embedding = DataEmbedding(\n",
    "            configs.dec_in,\n",
    "            configs.d_model,\n",
    "            configs.embed,\n",
    "            configs.freq,\n",
    "            configs.dropout,\n",
    "        )\n",
    "\n",
    "        # Encoder\n",
    "        if configs.version == \"Wavelet\":\n",
    "            enc_self_attention = WaveletAttention(\n",
    "                in_channels=configs.d_model,\n",
    "                out_channels=configs.d_model,\n",
    "                seq_len_q=configs.seq_len,\n",
    "                seq_len_kv=configs.seq_len,\n",
    "                ich=configs.d_model,\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "            dec_self_attention = WaveletAttention(\n",
    "                in_channels=configs.d_model,\n",
    "                out_channels=configs.d_model,\n",
    "                seq_len_q=configs.seq_len // 2 + configs.pred_len,\n",
    "                seq_len_kv=configs.seq_len // 2 + configs.pred_len,\n",
    "                ich=configs.d_model,\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "            dec_cross_attention = WaveletAttention(\n",
    "                in_channels=configs.d_model,\n",
    "                out_channels=configs.d_model,\n",
    "                seq_len_q=configs.seq_len // 2 + configs.pred_len,\n",
    "                seq_len_kv=configs.seq_len,\n",
    "                ich=configs.d_model,\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "        elif configs.version == \"Fourier\":\n",
    "            enc_self_attention = FourierAttention(\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "            dec_self_attention = FourierAttention(\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "            dec_cross_attention = FourierAttention(\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "        elif configs.version == \"Time\":\n",
    "            enc_self_attention = FullAttention(\n",
    "                False,\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                attention_dropout=configs.dropout,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "            dec_self_attention = FullAttention(\n",
    "                True,\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                attention_dropout=configs.dropout,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "            dec_cross_attention = FullAttention(\n",
    "                False,\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                attention_dropout=configs.dropout,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(enc_self_attention, configs.d_model),\n",
    "                    configs.d_model,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation,\n",
    "                )\n",
    "                for l in range(2)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model),\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(dec_self_attention, configs.d_model),\n",
    "                    AttentionLayer(dec_cross_attention, configs.d_model),\n",
    "                    configs.d_model,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation,\n",
    "                )\n",
    "                for l in range(1)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model),\n",
    "            projection=nn.Linear(configs.d_model, configs.c_out, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_enc,\n",
    "        x_mark_enc,\n",
    "        x_dec,\n",
    "        x_mark_dec,\n",
    "        enc_self_mask=None,\n",
    "        dec_self_mask=None,\n",
    "        dec_enc_mask=None,\n",
    "    ):\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        enc_out, attn_e = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
    "\n",
    "        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
    "        dec_out, attn_d = self.decoder(\n",
    "            dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask\n",
    "        )\n",
    "\n",
    "        if self.output_attention:\n",
    "            return dec_out[:, -self.pred_len :, :], (attn_e, attn_d)\n",
    "        else:\n",
    "            return dec_out[:, -self.pred_len :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP\n",
    "\n",
    "3-layer MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.label_len = configs.label_len\n",
    "        self.pred_len = configs.pred_len\n",
    "\n",
    "        # Encoder\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(configs.seq_len, configs.d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(configs.d_model, configs.d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(configs.d_model, configs.pred_len),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_enc,\n",
    "        x_mark_enc,\n",
    "        x_dec,\n",
    "        x_mark_dec,\n",
    "        enc_self_mask=None,\n",
    "        dec_self_mask=None,\n",
    "        dec_enc_mask=None,\n",
    "    ):\n",
    "        out = self.mlp(x_enc.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDformer\n",
    "\n",
    "First apply seasonal-trend decomposition, then use MLP to model the trend, and Fourier attention to model the seasonal part, and add them together to obtain the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer for seasonality, MLP for trend\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(TDformer, self).__init__()\n",
    "        self.version = configs.version\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.label_len = configs.label_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.output_attention = configs.output_attention\n",
    "        self.output_stl = configs.output_stl\n",
    "        self.device = configs.device\n",
    "\n",
    "        # Decomp\n",
    "        kernel_size = configs.moving_avg\n",
    "        if isinstance(kernel_size, list):\n",
    "            self.decomp = series_decomp_multi(kernel_size)\n",
    "        else:\n",
    "            self.decomp = series_decomp(kernel_size)\n",
    "\n",
    "        # Embedding\n",
    "        self.enc_seasonal_embedding = DataEmbedding(\n",
    "            configs.enc_in,\n",
    "            configs.d_model,\n",
    "            configs.embed,\n",
    "            configs.freq,\n",
    "            configs.dropout,\n",
    "        )\n",
    "        self.dec_seasonal_embedding = DataEmbedding(\n",
    "            configs.dec_in,\n",
    "            configs.d_model,\n",
    "            configs.embed,\n",
    "            configs.freq,\n",
    "            configs.dropout,\n",
    "        )\n",
    "        # Encoder\n",
    "        if configs.version == \"Wavelet\":\n",
    "            enc_self_attention = WaveletAttention(\n",
    "                in_channels=configs.d_model,\n",
    "                out_channels=configs.d_model,\n",
    "                seq_len_q=configs.seq_len,\n",
    "                seq_len_kv=configs.seq_len,\n",
    "                ich=configs.d_model,\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "            dec_self_attention = WaveletAttention(\n",
    "                in_channels=configs.d_model,\n",
    "                out_channels=configs.d_model,\n",
    "                seq_len_q=configs.seq_len // 2 + configs.pred_len,\n",
    "                seq_len_kv=configs.seq_len // 2 + configs.pred_len,\n",
    "                ich=configs.d_model,\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "            dec_cross_attention = WaveletAttention(\n",
    "                in_channels=configs.d_model,\n",
    "                out_channels=configs.d_model,\n",
    "                seq_len_q=configs.seq_len // 2 + configs.pred_len,\n",
    "                seq_len_kv=configs.seq_len,\n",
    "                ich=configs.d_model,\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "        elif configs.version == \"Fourier\":\n",
    "            enc_self_attention = FourierAttention(\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "            dec_self_attention = FourierAttention(\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "            dec_cross_attention = FourierAttention(\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "        elif configs.version == \"Time\":\n",
    "            enc_self_attention = FullAttention(\n",
    "                False,\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                attention_dropout=configs.dropout,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "            dec_self_attention = FullAttention(\n",
    "                True,\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                attention_dropout=configs.dropout,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "            dec_cross_attention = FullAttention(\n",
    "                False,\n",
    "                T=configs.temp,\n",
    "                activation=configs.activation,\n",
    "                attention_dropout=configs.dropout,\n",
    "                output_attention=configs.output_attention,\n",
    "            )\n",
    "        # Encoder\n",
    "        self.seasonal_encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(enc_self_attention, configs.d_model),\n",
    "                    configs.d_model,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation,\n",
    "                )\n",
    "                for l in range(2)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model),\n",
    "        )\n",
    "        # Decoder\n",
    "        self.seasonal_decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(dec_self_attention, configs.d_model),\n",
    "                    AttentionLayer(dec_cross_attention, configs.d_model),\n",
    "                    configs.d_model,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation,\n",
    "                )\n",
    "                for l in range(1)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model),\n",
    "            projection=nn.Linear(configs.d_model, configs.c_out, bias=True),\n",
    "        )\n",
    "\n",
    "        # Encoder\n",
    "        self.trend = nn.Sequential(\n",
    "            nn.Linear(configs.seq_len, configs.d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(configs.d_model, configs.d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(configs.d_model, configs.pred_len),\n",
    "        )\n",
    "\n",
    "        self.revin_trend = RevIN(configs.enc_in).to(self.device)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_enc,\n",
    "        x_mark_enc,\n",
    "        x_dec,\n",
    "        x_mark_dec,\n",
    "        enc_self_mask=None,\n",
    "        dec_self_mask=None,\n",
    "        dec_enc_mask=None,\n",
    "    ):\n",
    "        # decomp init\n",
    "        zeros = torch.zeros(\n",
    "            [x_dec.shape[0], self.pred_len, x_dec.shape[2]]\n",
    "        ).to(\n",
    "            self.device\n",
    "        )  # cuda()\n",
    "        seasonal_enc, trend_enc = self.decomp(x_enc)\n",
    "        seasonal_dec = F.pad(\n",
    "            seasonal_enc[:, -self.label_len :, :], (0, 0, 0, self.pred_len)\n",
    "        )\n",
    "\n",
    "        # seasonal\n",
    "        enc_out = self.enc_seasonal_embedding(seasonal_enc, x_mark_enc)\n",
    "        enc_out, attn_e = self.seasonal_encoder(\n",
    "            enc_out, attn_mask=enc_self_mask\n",
    "        )\n",
    "\n",
    "        dec_out = self.dec_seasonal_embedding(seasonal_dec, x_mark_dec)\n",
    "        seasonal_out, attn_d = self.seasonal_decoder(\n",
    "            dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask\n",
    "        )\n",
    "        seasonal_out = seasonal_out[:, -self.pred_len :, :]\n",
    "\n",
    "        seasonal_ratio = seasonal_enc.abs().mean(\n",
    "            dim=1\n",
    "        ) / seasonal_out.abs().mean(dim=1)\n",
    "        seasonal_ratio = seasonal_ratio.unsqueeze(1).expand(\n",
    "            -1, self.pred_len, -1\n",
    "        )\n",
    "\n",
    "        # trend\n",
    "        trend_enc = self.revin_trend(trend_enc, \"norm\")\n",
    "        trend_out = self.trend(trend_enc.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        trend_out = self.revin_trend(trend_out, \"denorm\")\n",
    "\n",
    "        # final\n",
    "        dec_out = trend_out + seasonal_ratio * seasonal_out\n",
    "\n",
    "        if self.output_attention:\n",
    "            return dec_out, (attn_e, attn_d)\n",
    "        elif self.output_stl:\n",
    "            return (\n",
    "                dec_out,\n",
    "                trend_enc,\n",
    "                seasonal_enc,\n",
    "                trend_out,\n",
    "                seasonal_ratio * seasonal_out,\n",
    "            )\n",
    "        else:\n",
    "            return dec_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main function\n",
    "\n",
    "main parameters to change:\n",
    "\n",
    "1. fix_seed: random seed\n",
    "2. dataset: choices: electricity.csv, exchange_rate.csv, traffic.csv, weather.csv, sin.csv, vary.csv, linear.csv, spikes.csv. Data will be automatically downloaded for the first time.\n",
    "3. r: training ratio\n",
    "4. pred: prediction horizon\n",
    "5. v: attention version (Time, Fourier, Wavelet)\n",
    "6. model: Transformer, MLP, TDformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    class Namespace:\n",
    "        def __init__(self, **kwargs):\n",
    "            self.__dict__.update(kwargs)\n",
    "\n",
    "    dim_dict = {\n",
    "        \"ETTm2.csv\": 7,\n",
    "        \"electricity.csv\": 321,\n",
    "        \"exchange_rate.csv\": 8,\n",
    "        \"traffic.csv\": 862,\n",
    "        \"weather.csv\": 21,\n",
    "        \"sin.csv\": 1,\n",
    "        \"vary.csv\": 1,\n",
    "        \"linear.csv\": 1,\n",
    "        \"spikes.csv\": 1,\n",
    "    }\n",
    "    model_dict = {\"MLP\": MLP, \"TDformer\": TDformer, \"Transformer\": Transformer}\n",
    "\n",
    "    if not os.path.exists(\"./dataset\"):\n",
    "        print(\n",
    "            \"first create './dataset/' in the current folder, then download the datasets from 'https://drive.google.com/drive/u/0/folders/1UD5jqDtJnliBhghkhM9CVqb49ZAhr1KB'\"\n",
    "        )\n",
    "        assert 0\n",
    "        # os.mkdir('./dataset')\n",
    "        # import gdown\n",
    "        # url = 'https://drive.google.com/drive/u/0/folders/1UD5jqDtJnliBhghkhM9CVqb49ZAhr1KB'\n",
    "        # gdown.download_folder(url, remaining_ok=True)\n",
    "\n",
    "    if not os.path.exists(\"./log\"):\n",
    "        os.mkdir(\"./log\")\n",
    "\n",
    "    for fix_seed in [0, 1, 42, 2021, 2022]:\n",
    "        random.seed(fix_seed)\n",
    "        torch.manual_seed(fix_seed)\n",
    "        np.random.seed(fix_seed)\n",
    "\n",
    "        for dataset in [\"exchange_rate.csv\"]:\n",
    "            # for r in [0.0205,0.021,0.0215,0.022,0.03]: # ratio for sin.csv\n",
    "            # for r in [0.0225,0.025,0.03,0.04,0.06]: # ratio for vary.csv\n",
    "            # for r in [0.5]: # ratio for linear.csv and spikes.csv\n",
    "            for r in [0.7]:  # ratio for real-world datasets\n",
    "                for pred in [96, 192, 336, 720]:\n",
    "                    for v in [\n",
    "                        \"Fourier\"\n",
    "                    ]:  # Attention types: Time, Fourier, Wavelet\n",
    "                        args = Namespace(\n",
    "                            model=\"TDformer\",  # Transformer, MLP, TDformer\n",
    "                            activation=\"softmax\",\n",
    "                            seq_len=96,  # 96,\n",
    "                            label_len=48,  # 48,\n",
    "                            temp=1,\n",
    "                            pred_len=pred,\n",
    "                            version=v,\n",
    "                            data_path=dataset,\n",
    "                            ratio=r,\n",
    "                            features=\"M\",\n",
    "                            target=\"OT\",\n",
    "                            freq=\"h\",\n",
    "                            patience=20,\n",
    "                            enc_in=dim_dict[dataset],\n",
    "                            dec_in=dim_dict[dataset],\n",
    "                            c_out=dim_dict[dataset],\n",
    "                            adjust=False,\n",
    "                            des=\"\",\n",
    "                            d_model=512,\n",
    "                            d_ff=2048,\n",
    "                            embed=\"timeF\",\n",
    "                            dropout=0.05,\n",
    "                            output_attention=False,\n",
    "                            output_stl=False,\n",
    "                            learning_rate=0.0001,\n",
    "                            lradj=\"type1\",\n",
    "                            moving_avg=[24],\n",
    "                            gpu=0,\n",
    "                        )\n",
    "                        args.des = (\n",
    "                            args.data_path[:-4]\n",
    "                            + str(args.ratio)\n",
    "                            + args.activation\n",
    "                            + \"temp\"\n",
    "                            + str(args.temp)\n",
    "                            + args.model\n",
    "                            + args.version\n",
    "                            + str(args.pred_len)\n",
    "                            + \"seed\"\n",
    "                            + str(fix_seed)\n",
    "                        )\n",
    "\n",
    "                        args.device = torch.device(\n",
    "                            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "                        )\n",
    "\n",
    "                        model = (\n",
    "                            model_dict[args.model](args)\n",
    "                            .float()\n",
    "                            .to(args.device)\n",
    "                        )\n",
    "\n",
    "                        exp = Exp_Main(args, model)  # set experiments\n",
    "                        exp.train()\n",
    "\n",
    "                        exp.test(test=1)\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('tensorboard')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57b906eaf3f7e8e516d52119501360ae3c142bd7be311060e1ed20cea4e857c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
