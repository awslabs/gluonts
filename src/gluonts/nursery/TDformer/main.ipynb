{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import * # embedding layers, normalization layer\n",
    "from data import * # data loader\n",
    "from utils import *\n",
    "from exp import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-domain attention\n",
    "\n",
    "Denote input queries, keys and values as $\\mathbf{q} \\in \\mathbb{R}^{L \\times D}, \\mathbf{k} \\in \\mathbb{R}^{L \\times D}, \\mathbf{v} \\in \\mathbb{R}^{L \\times D}$, which are transformed from input $\\mathbf{x}$ through linear embeddings. Denote output of attention module as $\\mathbf{o} ( \\mathbf{q}, \\mathbf{k}, \\mathbf{v} ) \\in \\mathbb{R}^{L \\times D}$. Time-domain attention calculates attention in the original time domain as follows:\n",
    "\n",
    "$$\\mathbf{o} ( \\mathbf{q}, \\mathbf{k}, \\mathbf{v} ) = \\sigma \\left(\\frac{\\mathbf{q}\\mathbf{k}^T}{\\sqrt{d_q}}\\right)\\mathbf{v}$$\n",
    "\n",
    "where $d_q$ is the dimension for queries that serves as normalization term in attention operation, and $\\sigma(\\cdot)$ represents activation function. When  $\\sigma(\\cdot)=\\mathrm{softmax}(\\cdot)$ ($\\mathrm{softmax}(\\mathbf{x}) = \\frac{e^{x_i}}{\\sum_i e^{x_i}}$), we have softmax attention: $\\mathbf{o} ( \\mathbf{q}, \\mathbf{k}, \\mathbf{v} ) = \\mathrm{softmax} \\left({\\mathbf{q}\\mathbf{k}^T}/{\\sqrt{d_q}}\\right)\\mathbf{v}$. When $\\sigma(\\cdot)=\\mathrm{Id}(\\cdot)$ (identity mapping), we have linear attention: $\\mathbf{o}( \\mathbf{q}, \\mathbf{k}, \\mathbf{v} ) = \\left(\\mathbf{q}\\mathbf{k}^T/\\sqrt{d_q}\\right)\\mathbf{v}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import os\n",
    "\n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "\n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=3, scale=None, attention_dropout=0.1, T=1, activation='softmax', output_attention=False):\n",
    "        super(FullAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.activation = activation\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "        self.T = T\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / sqrt(E)\n",
    "        \n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys) * scale\n",
    "        \n",
    "        if self.activation == 'softmax':\n",
    "            if self.mask_flag:\n",
    "                if attn_mask is None:\n",
    "                    attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "                scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "            A = self.dropout(torch.softmax(scores / self.T, dim=-1))\n",
    "            V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "        \n",
    "        elif self.activation == 'linear':\n",
    "            V = torch.einsum(\"bhls,bshd->blhd\", scores, values)\n",
    "            \n",
    "        elif self.activation == 'linear_norm':\n",
    "            mins = scores.min(dim=-1)[0].unsqueeze(-1).expand(-1,-1,-1,scores.shape[3])\n",
    "            scores = scores - mins + 1e-8\n",
    "            \n",
    "            if self.mask_flag:\n",
    "                if attn_mask is None:\n",
    "                    attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "                scores.masked_fill_(attn_mask.mask, 0)\n",
    "          \n",
    "            sums = scores.sum(dim=-1).unsqueeze(-1).expand(-1,-1,-1,scores.shape[3])\n",
    "            scores /= sums\n",
    "            V = torch.einsum(\"bhls,bshd->blhd\", scores, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return (V.contiguous(), A)\n",
    "        else:\n",
    "            return (V.contiguous(), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier-domain attention\n",
    "\n",
    "Fourier attention first converts queries, keys, and values with Fourier Transform, performs a similar attention mechanism in the frequency domain, and finally converts the results back to the time domain using inverse Fourier transform. Let $\\mathcal{F}(\\cdot), \\mathcal{F}^{-1}(\\cdot)$ denote Fourier transform and inverse Fourier transform, then Fourier attention is $\\mathbf{o} ( \\mathbf{q}, \\mathbf{k}, \\mathbf{v} ) = \\mathcal{F}^{-1} \\Big(\\sigma\\big({\\mathcal{F}(\\mathbf{q})\\overline{\\mathcal{F}(\\mathbf{k}}})^T/{\\sqrt{d_q}}\\big)\\mathcal{F}(\\mathbf{v})\\Big)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierAttention(nn.Module):\n",
    "    def __init__(self, T=1, activation='softmax', output_attention=False):\n",
    "        super(FourierAttention, self).__init__()\n",
    "        print(' fourier enhanced cross attention used!')\n",
    "        \"\"\"\n",
    "        1D Fourier Cross Attention layer. It does FFT, linear transform, attention mechanism and Inverse FFT.    \n",
    "        \"\"\"\n",
    "        self.activation = activation\n",
    "        self.output_attention = output_attention\n",
    "        self.T = T\n",
    "        \n",
    "    def forward(self, q, k, v, mask):\n",
    "        # size = [B, L, H, E]\n",
    "        B, L, H, E = q.shape\n",
    "        _, S, H, E = k.shape\n",
    "        xq = q.permute(0, 2, 3, 1)  # size = [B, H, E, L]\n",
    "        xk = k.permute(0, 2, 3, 1)\n",
    "        xv = v.permute(0, 2, 3, 1)\n",
    "\n",
    "        xq_ft_ = torch.fft.rfft(xq, dim=-1, norm='ortho')\n",
    "        xk_ft_ = torch.fft.rfft(xk, dim=-1, norm='ortho')\n",
    "        xv_ft_ = torch.fft.rfft(xv, dim=-1, norm='ortho')\n",
    "\n",
    "        xqk_ft = torch.einsum(\"bhex,bhey->bhxy\", xq_ft_, torch.conj(xk_ft_)) / sqrt(E)\n",
    "            \n",
    "        if self.activation == 'softmax':\n",
    "            xqk_ft = torch.softmax(xqk_ft.abs() / self.T, dim=-1)\n",
    "            xqk_ft = torch.complex(xqk_ft, torch.zeros_like(xqk_ft))       \n",
    "            xqkv_ft = torch.einsum(\"bhxy,bhey->bhex\", xqk_ft, xv_ft_)\n",
    "         \n",
    "        elif self.activation == 'linear':\n",
    "            xqkv_ft = torch.einsum(\"bhxy,bhey->bhex\", xqk_ft, xv_ft_)\n",
    "            \n",
    "        elif self.activation == 'linear_norm':\n",
    "            mins_real = xqk_ft.real.min(dim=-1)[0].unsqueeze(-1).expand(-1,-1,-1,xqk_ft.shape[3])\n",
    "            xqk_ft_real = xqk_ft.real - mins_real\n",
    "            sums_real = xqk_ft_real.sum(dim=-1).unsqueeze(-1).expand(-1,-1,-1,xqk_ft.shape[3])\n",
    "            xqk_ft_real /= sums_real\n",
    "            \n",
    "            mins_imag = xqk_ft.imag.min(dim=-1)[0].unsqueeze(-1).expand(-1,-1,-1,xqk_ft.shape[3])\n",
    "            xqk_ft_imag = xqk_ft.imag - mins_imag\n",
    "            sums_imag = xqk_ft_imag.sum(dim=-1).unsqueeze(-1).expand(-1,-1,-1,xqk_ft.shape[3])\n",
    "            xqk_ft_imag /= sums_imag\n",
    "            \n",
    "            xqkv_ft_real = torch.einsum(\"bhxy,bhey->bhex\", xqk_ft_real, xv_ft_.real)\n",
    "            xqkv_ft_imag = torch.einsum(\"bhxy,bhey->bhex\", xqk_ft_imag, xv_ft_.imag)       \n",
    "            xqkv_ft = torch.complex(xqkv_ft_real, xqkv_ft_imag)\n",
    "        \n",
    "        elif self.activation == 'linear_norm_abs':\n",
    "            xqk_ft = xqk_ft.abs() / xqk_ft.abs().sum(dim=-1).unsqueeze(-1).expand(-1,-1,-1,xqk_ft.shape[3])\n",
    "            xqk_ft = torch.complex(xqk_ft, torch.zeros_like(xqk_ft))       \n",
    "            xqkv_ft = torch.einsum(\"bhxy,bhey->bhex\", xqk_ft, xv_ft_)\n",
    "            \n",
    "        elif self.activation == 'linear_norm_real':\n",
    "            mins_real = xqk_ft.real.min(dim=-1)[0].unsqueeze(-1).expand(-1,-1,-1,xqk_ft.shape[3])\n",
    "            xqk_ft_real = xqk_ft.real - mins_real\n",
    "            sums_real = xqk_ft_real.sum(dim=-1).unsqueeze(-1).expand(-1,-1,-1,xqk_ft.shape[3])\n",
    "            xqk_ft_real /= sums_real\n",
    "        \n",
    "            xqk_ft = torch.complex(xqk_ft_real, torch.zeros_like(xqk_ft_real))       \n",
    "            xqkv_ft = torch.einsum(\"bhxy,bhey->bhex\", xqk_ft, xv_ft_)\n",
    "      \n",
    "        out = torch.fft.irfft(xqkv_ft, n=L, dim=-1, norm='ortho').permute(0, 3, 1, 2)\n",
    "        \n",
    "        if self.output_attention == False:\n",
    "            return (out, None)\n",
    "        else:\n",
    "            return (out, (xqk_ft_real, xqk_ft_imag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet-domain attention\n",
    "\n",
    "Wavelet transform applies wavelet decomposition and reconstruction to obtain signals of different scales. Wavelet attention performs attention calculation to decomposed queries, keys, and values in each scale, and reconstructs the output from attention results in each scale. Let $\\mathcal{W}(\\cdot), \\mathcal{W}^{-1}(\\cdot)$ denote wavelet decomposition and wavelet reconstruction, then wavelet attention is $\\mathbf{o} ( \\mathbf{q}, \\mathbf{k}, \\mathbf{v} ) = \\mathcal{W}^{-1}\\Big(\\sigma\\left({\\mathcal{W}(\\mathbf{q})\\mathcal{W}(\\mathbf{k}^T})/{\\sqrt{d_q}}\\right)\\mathcal{W}(\\mathbf{v})\\Big)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparseKernel1d(nn.Module):\n",
    "    def __init__(self,\n",
    "                 k, c=1,\n",
    "                 nl = 1,\n",
    "                 initializer = None,\n",
    "                 **kwargs):\n",
    "        super(sparseKernel1d,self).__init__()\n",
    "       \n",
    "        self.k = k\n",
    "        self.Li = nn.Linear(c*k, 128)\n",
    "        self.conv = self.convBlock(c*k, 128)\n",
    "        self.Lo = nn.Linear(128, c*k)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        B, N, c, ich = x.shape # (B, N, c, k)\n",
    "        x = x.view(B, N, -1)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.Lo(x)\n",
    "        x = x.view(B, N, c, ich)\n",
    "        return x\n",
    "    \n",
    "    def convBlock(self, ich, och):\n",
    "        net = nn.Sequential(\n",
    "            nn.Conv1d(ich, och, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        return net    \n",
    "\n",
    "class WaveletAttention(nn.Module):\n",
    "   \n",
    "    def __init__(self, in_channels, out_channels, seq_len_q, seq_len_kv, c=64,\n",
    "                 k=8, ich=512,\n",
    "                 L=3,\n",
    "                 base='legendre',\n",
    "                 initializer=None, T=1, activation='softmax', output_attention=False, \n",
    "                 **kwargs):\n",
    "        super(WaveletAttention, self).__init__()\n",
    "        print('base', base)\n",
    "\n",
    "        self.c = c\n",
    "        self.k = k\n",
    "        self.L = L\n",
    "        self.T = T\n",
    "        self.activation = activation\n",
    "        H0, H1, G0, G1, PHI0, PHI1 = get_filter(base, k)\n",
    "        H0r = H0 @ PHI0\n",
    "        G0r = G0 @ PHI0\n",
    "        H1r = H1 @ PHI1\n",
    "        G1r = G1 @ PHI1\n",
    "\n",
    "        H0r[np.abs(H0r) < 1e-8] = 0\n",
    "        H1r[np.abs(H1r) < 1e-8] = 0\n",
    "        G0r[np.abs(G0r) < 1e-8] = 0\n",
    "        G1r[np.abs(G1r) < 1e-8] = 0\n",
    "        self.max_item = 3\n",
    "\n",
    "        self.register_buffer('ec_s', torch.Tensor(\n",
    "            np.concatenate((H0.T, H1.T), axis=0)))\n",
    "        self.register_buffer('ec_d', torch.Tensor(\n",
    "            np.concatenate((G0.T, G1.T), axis=0)))\n",
    "\n",
    "        self.register_buffer('rc_e', torch.Tensor(\n",
    "            np.concatenate((H0r, G0r), axis=0)))\n",
    "        self.register_buffer('rc_o', torch.Tensor(\n",
    "            np.concatenate((H1r, G1r), axis=0)))\n",
    "\n",
    "        self.Lk = nn.Linear(ich, c * k)\n",
    "        self.Lq = nn.Linear(ich, c * k)\n",
    "        self.Lv = nn.Linear(ich, c * k)\n",
    "        self.out = nn.Linear(c * k, ich)\n",
    "      \n",
    "        self.output_attention = output_attention\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        B, N, H, E = q.shape  # (B, N, H, E) torch.Size([3, 768, 8, 2])\n",
    "        _, S, _, _ = k.shape  # (B, S, H, E) torch.Size([3, 96, 8, 2])\n",
    "\n",
    "        q = q.view(q.shape[0], q.shape[1], -1) # (B, N, H*E)\n",
    "        k = k.view(k.shape[0], k.shape[1], -1)\n",
    "        v = v.view(v.shape[0], v.shape[1], -1)\n",
    "        q = self.Lq(q)\n",
    "        q = q.view(q.shape[0], q.shape[1], self.c, self.k) # (B, N, E, H)\n",
    "        k = self.Lk(k)\n",
    "        k = k.view(k.shape[0], k.shape[1], self.c, self.k)\n",
    "        v = self.Lv(v)\n",
    "        v = v.view(v.shape[0], v.shape[1], self.c, self.k)\n",
    "\n",
    "        if N > S:\n",
    "            zeros = torch.zeros_like(q[:, :(N - S), :]).float()\n",
    "            v = torch.cat([v, zeros], dim=1)\n",
    "            k = torch.cat([k, zeros], dim=1)\n",
    "        else:\n",
    "            v = v[:, :N, :, :]\n",
    "            k = k[:, :N, :, :]\n",
    "        ns = math.floor(np.log2(N))\n",
    "        nl = pow(2, math.ceil(np.log2(N)))\n",
    "        extra_q = q[:, 0:nl - N, :, :]\n",
    "        extra_k = k[:, 0:nl - N, :, :]\n",
    "        extra_v = v[:, 0:nl - N, :, :]\n",
    "        q = torch.cat([q, extra_q], 1)\n",
    "        k = torch.cat([k, extra_k], 1)\n",
    "        v = torch.cat([v, extra_v], 1)\n",
    "\n",
    "        Ud = torch.jit.annotate(List[Tensor], [])\n",
    "        Us = torch.jit.annotate(List[Tensor], [])\n",
    "        \n",
    "        attn_d_list, attn_s_list = [], []\n",
    "        \n",
    "        for i in range(ns - self.L):\n",
    "            dq, q = self.wavelet_transform(q)\n",
    "            dk, k = self.wavelet_transform(k)\n",
    "            dv, v = self.wavelet_transform(v) # (B, N, E, H)\n",
    "            \n",
    "            scores_d = torch.einsum(\"bxeh,byeh->bhxy\", dq, dk) / sqrt(E)\n",
    "            \n",
    "            if self.activation == 'softmax':\n",
    "                attn_d = F.softmax(scores_d / self.T, dim=-1) #(B,H,q,k)\n",
    "            elif self.activation == 'linear':\n",
    "                attn_d = scores_d #(B,H,q,k)\n",
    "            elif self.activation == 'linear_norm':\n",
    "                attn_d = scores_d #(B,H,q,k)\n",
    "                mins = attn_d.min(dim=-1).unsqueeze(-1).expand(-1,-1,-1,attn_d.shape[3])\n",
    "                attn_d -= mins\n",
    "                sums = attn_d.sum(dim=-1).unsqueeze(-1).expand(-1,-1,-1,attn_d.shape[3])\n",
    "                attn_d /= sums\n",
    "            Ud += [torch.einsum(\"bhxy,byeh->bxeh\", attn_d, dv)]\n",
    "            attn_d_list.append(attn_d)\n",
    "            \n",
    "            scores_s = torch.einsum(\"bxeh,byeh->bhxy\", q, k) / sqrt(E)\n",
    "            \n",
    "            if self.activation == 'softmax':\n",
    "                attn_s = F.softmax(scores_s / self.T, dim=-1) #(B,H,q,k)\n",
    "            elif self.activation == 'linear':\n",
    "                attn_s = scores_s #(B,H,q,k)\n",
    "            elif self.activation == 'linear_norm':\n",
    "                attn_s = scores_s #(B,H,q,k)\n",
    "                mins = attn_s.min(dim=-1).unsqueeze(-1).expand(-1,-1,-1,attn_s.shape[3])\n",
    "                attn_s -= mins\n",
    "                sums = attn_s.sum(dim=-1).unsqueeze(-1).expand(-1,-1,-1,attn_s.shape[3])\n",
    "                attn_s /= sums\n",
    "            Us += [torch.einsum(\"bhxy,byeh->bxeh\", attn_s, v)]\n",
    "            attn_s_list.append(attn_s)\n",
    "           \n",
    "        # reconstruct\n",
    "        for i in range(ns - 1 - self.L, -1, -1):\n",
    "            v = v + Us[i]\n",
    "            v = torch.cat((v, Ud[i]), -1)\n",
    "            v = self.evenOdd(v)\n",
    "        v = self.out(v[:, :N, :, :].contiguous().view(B, N, -1))\n",
    "        if self.output_attention == False:\n",
    "            return (v.contiguous(), None)\n",
    "        else:\n",
    "            return (v.contiguous(), (attn_s_list, attn_d_list))\n",
    "\n",
    "    def wavelet_transform(self, x):\n",
    "        xa = torch.cat([x[:, ::2, :, :],\n",
    "                        x[:, 1::2, :, :],\n",
    "                        ], -1)\n",
    "        d = torch.matmul(xa, self.ec_d)\n",
    "        s = torch.matmul(xa, self.ec_s)\n",
    "        return d, s\n",
    "\n",
    "    def evenOdd(self, x):\n",
    "        B, N, c, ich = x.shape  # (B, N, c, k)\n",
    "        assert ich == 2 * self.k\n",
    "        x_e = torch.matmul(x, self.rc_e)\n",
    "        x_o = torch.matmul(x, self.rc_o)\n",
    "\n",
    "        x = torch.zeros(B, N * 2, c, self.k,\n",
    "                        device=x.device)\n",
    "        x[..., ::2, :, :] = x_e\n",
    "        x[..., 1::2, :, :] = x_o\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer\n",
    "\n",
    "The vanilla Transformer, can specify which attention to use (time, Fourier, wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Vanilla Transformer with O(L^2) complexity\n",
    "    \"\"\"\n",
    "    def __init__(self, configs):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.output_attention = configs.output_attention\n",
    "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                            configs.dropout)\n",
    "        self.dec_embedding = DataEmbedding(configs.dec_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                            configs.dropout)\n",
    "            \n",
    "        # Encoder\n",
    "        if configs.version == 'Wavelet':\n",
    "            enc_self_attention = WaveletAttention(in_channels=configs.d_model,\n",
    "                                                  out_channels=configs.d_model,\n",
    "                                                  seq_len_q=configs.seq_len,\n",
    "                                                  seq_len_kv=configs.seq_len,\n",
    "                                                  ich=configs.d_model,\n",
    "                                                  T=configs.temp, \n",
    "                                                  activation=configs.activation,\n",
    "                                                  output_attention=configs.output_attention)\n",
    "            dec_self_attention = WaveletAttention(in_channels=configs.d_model,\n",
    "                                                  out_channels=configs.d_model,\n",
    "                                                  seq_len_q=configs.seq_len // 2 + configs.pred_len,\n",
    "                                                  seq_len_kv=configs.seq_len // 2 + configs.pred_len,\n",
    "                                                  ich=configs.d_model,  \n",
    "                                                  T=configs.temp, \n",
    "                                                  activation=configs.activation,\n",
    "                                                  output_attention=configs.output_attention)\n",
    "            dec_cross_attention = WaveletAttention(in_channels=configs.d_model,\n",
    "                                                  out_channels=configs.d_model,\n",
    "                                                  seq_len_q=configs.seq_len // 2 + configs.pred_len,\n",
    "                                                  seq_len_kv=configs.seq_len,\n",
    "                                                  ich=configs.d_model,    \n",
    "                                                  T=configs.temp, \n",
    "                                                  activation=configs.activation,\n",
    "                                                  output_attention=configs.output_attention)\n",
    "        elif configs.version == 'Fourier':\n",
    "            enc_self_attention = FourierAttention(T=configs.temp, activation=configs.activation, \n",
    "                                                  output_attention=configs.output_attention)\n",
    "            dec_self_attention = FourierAttention(T=configs.temp, activation=configs.activation, \n",
    "                                                  output_attention=configs.output_attention)\n",
    "            dec_cross_attention = FourierAttention(T=configs.temp, activation=configs.activation, \n",
    "                                                   output_attention=configs.output_attention)\n",
    "        elif configs.version == 'Time':\n",
    "            enc_self_attention = FullAttention(False, T=configs.temp, activation=configs.activation, \n",
    "                                               attention_dropout=configs.dropout,output_attention=configs.output_attention)\n",
    "            dec_self_attention = FullAttention(True, T=configs.temp, activation=configs.activation, \n",
    "                                               attention_dropout=configs.dropout, output_attention=configs.output_attention)\n",
    "            dec_cross_attention = FullAttention(False, T=configs.temp, activation=configs.activation, \n",
    "                                                attention_dropout=configs.dropout,output_attention=configs.output_attention)\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        enc_self_attention,\n",
    "                        configs.d_model),\n",
    "                    configs.d_model,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation\n",
    "                ) for l in range(2)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        dec_self_attention,\n",
    "                        configs.d_model),\n",
    "                    AttentionLayer(\n",
    "                        dec_cross_attention,\n",
    "                        configs.d_model),\n",
    "                    configs.d_model,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation,\n",
    "                )\n",
    "                for l in range(1)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model),\n",
    "            projection=nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
    "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
    "        \n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        enc_out, attn_e = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
    "     \n",
    "        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
    "        dec_out, attn_d = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n",
    "  \n",
    "        if self.output_attention:\n",
    "            return dec_out[:, -self.pred_len:, :], (attn_e, attn_d)\n",
    "        else:\n",
    "            return dec_out[:, -self.pred_len:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP\n",
    "\n",
    "3-layer MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.label_len = configs.label_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        \n",
    "        # Encoder\n",
    "        self.mlp = nn.Sequential(\n",
    "          nn.Linear(configs.seq_len, configs.d_model),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(configs.d_model, configs.d_model),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(configs.d_model, configs.pred_len)\n",
    "        )\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
    "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
    "        \n",
    "        out = self.mlp(x_enc.permute(0,2,1)).permute(0,2,1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDformer\n",
    "\n",
    "First apply seasonal-trend decomposition, then use MLP to model the trend, and Fourier attention to model the seasonal part, and add them together to obtain the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer for seasonality, MLP for trend\n",
    "    \"\"\"\n",
    "    def __init__(self, configs):\n",
    "        super(TDformer, self).__init__()\n",
    "        self.version = configs.version\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.label_len = configs.label_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.output_attention = configs.output_attention\n",
    "        self.output_stl = configs.output_stl\n",
    "        self.device = configs.device\n",
    "\n",
    "        # Decomp\n",
    "        kernel_size = configs.moving_avg\n",
    "        if isinstance(kernel_size, list):\n",
    "            self.decomp = series_decomp_multi(kernel_size)\n",
    "        else:\n",
    "            self.decomp = series_decomp(kernel_size)\n",
    "\n",
    "        # Embedding\n",
    "        self.enc_seasonal_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                            configs.dropout)\n",
    "        self.dec_seasonal_embedding = DataEmbedding(configs.dec_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                            configs.dropout)\n",
    "        # Encoder\n",
    "        if configs.version == 'Wavelet':\n",
    "            enc_self_attention = WaveletAttention(in_channels=configs.d_model,\n",
    "                                                  out_channels=configs.d_model,\n",
    "                                                  seq_len_q=configs.seq_len,\n",
    "                                                  seq_len_kv=configs.seq_len,\n",
    "                                                  ich=configs.d_model,\n",
    "                                                  T=configs.temp, \n",
    "                                                  activation=configs.activation,\n",
    "                                                  output_attention=configs.output_attention)\n",
    "            dec_self_attention = WaveletAttention(in_channels=configs.d_model,\n",
    "                                                  out_channels=configs.d_model,\n",
    "                                                  seq_len_q=configs.seq_len // 2 + configs.pred_len,\n",
    "                                                  seq_len_kv=configs.seq_len // 2 + configs.pred_len,\n",
    "                                                  ich=configs.d_model, \n",
    "                                                  T=configs.temp, \n",
    "                                                  activation=configs.activation,\n",
    "                                                  output_attention=configs.output_attention)\n",
    "            dec_cross_attention = WaveletAttention(in_channels=configs.d_model,\n",
    "                                                  out_channels=configs.d_model,\n",
    "                                                  seq_len_q=configs.seq_len // 2 + configs.pred_len,\n",
    "                                                  seq_len_kv=configs.seq_len,\n",
    "                                                  ich=configs.d_model,  \n",
    "                                                  T=configs.temp, \n",
    "                                                  activation=configs.activation,\n",
    "                                                  output_attention=configs.output_attention)\n",
    "        elif configs.version == 'Fourier':\n",
    "            enc_self_attention = FourierAttention(T=configs.temp, activation=configs.activation, \n",
    "                                                  output_attention=configs.output_attention)\n",
    "            dec_self_attention = FourierAttention(T=configs.temp, activation=configs.activation, \n",
    "                                                  output_attention=configs.output_attention)\n",
    "            dec_cross_attention = FourierAttention(T=configs.temp, activation=configs.activation, \n",
    "                                                   output_attention=configs.output_attention)\n",
    "        elif configs.version == 'Time':\n",
    "            enc_self_attention = FullAttention(False, T=configs.temp, activation=configs.activation, \n",
    "                                               attention_dropout=configs.dropout, \n",
    "                                               output_attention=configs.output_attention)\n",
    "            dec_self_attention = FullAttention(True, T=configs.temp, activation=configs.activation, \n",
    "                                               attention_dropout=configs.dropout, \n",
    "                                               output_attention=configs.output_attention)\n",
    "            dec_cross_attention = FullAttention(False, T=configs.temp, activation=configs.activation, \n",
    "                                                attention_dropout=configs.dropout,\n",
    "                                                output_attention=configs.output_attention)    \n",
    "        # Encoder\n",
    "        self.seasonal_encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        enc_self_attention,\n",
    "                        configs.d_model),\n",
    "                    configs.d_model,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation\n",
    "                ) for l in range(2)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.seasonal_decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        dec_self_attention,\n",
    "                        configs.d_model),\n",
    "                    AttentionLayer(\n",
    "                        dec_cross_attention,\n",
    "                        configs.d_model),\n",
    "                    configs.d_model,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation,\n",
    "                )\n",
    "                for l in range(1)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model),\n",
    "            projection=nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
    "        )\n",
    "        \n",
    "        # Encoder\n",
    "        self.trend = nn.Sequential(\n",
    "          nn.Linear(configs.seq_len, configs.d_model),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(configs.d_model, configs.d_model),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(configs.d_model, configs.pred_len)\n",
    "        )\n",
    "\n",
    "        self.revin_trend = RevIN(configs.enc_in).to(self.device)\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
    "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
    "\n",
    "        # decomp init\n",
    "        zeros = torch.zeros([x_dec.shape[0], self.pred_len, x_dec.shape[2]]).to(self.device)  # cuda()\n",
    "        seasonal_enc, trend_enc = self.decomp(x_enc)\n",
    "        seasonal_dec = F.pad(seasonal_enc[:, -self.label_len:, :], (0, 0, 0, self.pred_len))\n",
    "        \n",
    "        # seasonal\n",
    "        enc_out = self.enc_seasonal_embedding(seasonal_enc, x_mark_enc)\n",
    "        enc_out, attn_e = self.seasonal_encoder(enc_out, attn_mask=enc_self_mask)\n",
    "\n",
    "        dec_out = self.dec_seasonal_embedding(seasonal_dec, x_mark_dec)\n",
    "        seasonal_out, attn_d = self.seasonal_decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n",
    "        seasonal_out = seasonal_out[:, -self.pred_len:, :]\n",
    "\n",
    "        seasonal_ratio = seasonal_enc.abs().mean(dim=1) / seasonal_out.abs().mean(dim=1)\n",
    "        seasonal_ratio = seasonal_ratio.unsqueeze(1).expand(-1,self.pred_len,-1)\n",
    "        \n",
    "        # trend\n",
    "        trend_enc = self.revin_trend(trend_enc, 'norm')\n",
    "        trend_out = self.trend(trend_enc.permute(0,2,1)).permute(0,2,1)\n",
    "        trend_out = self.revin_trend(trend_out, 'denorm') \n",
    "       \n",
    "        # final\n",
    "        dec_out = trend_out + seasonal_ratio * seasonal_out\n",
    "        \n",
    "        if self.output_attention:\n",
    "            return dec_out, (attn_e, attn_d)\n",
    "        elif self.output_stl:\n",
    "            return dec_out, trend_enc, seasonal_enc, trend_out, seasonal_ratio * seasonal_out\n",
    "        else:\n",
    "            return dec_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main function\n",
    "\n",
    "main parameters to change:\n",
    "\n",
    "1. fix_seed: random seed\n",
    "2. dataset: choices: electricity.csv, exchange_rate.csv, traffic.csv, weather.csv, sin.csv, vary.csv, linear.csv, spikes.csv. Data will be automatically downloaded for the first time.\n",
    "3. r: training ratio\n",
    "4. pred: prediction horizon\n",
    "5. v: attention version (Time, Fourier, Wavelet)\n",
    "6. model: Transformer, MLP, TDformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    class Namespace:   \n",
    "        def __init__(self, **kwargs):\n",
    "            self.__dict__.update(kwargs)\n",
    "    \n",
    "    dim_dict = {'ETTm2.csv':7, 'electricity.csv':321, 'exchange_rate.csv':8, \\\n",
    "               'traffic.csv':862, 'weather.csv':21, 'sin.csv':1, 'vary.csv':1, 'linear.csv':1, 'spikes.csv':1}\n",
    "    model_dict = {'MLP': MLP, 'TDformer': TDformer, 'Transformer': Transformer}\n",
    "    \n",
    "    if not os.path.exists('./dataset'):\n",
    "        print(\"first create './dataset/' in the current folder, then download the datasets from 'https://drive.google.com/drive/u/0/folders/1UD5jqDtJnliBhghkhM9CVqb49ZAhr1KB'\")\n",
    "        assert 0\n",
    "        #os.mkdir('./dataset')\n",
    "        #import gdown\n",
    "        #url = 'https://drive.google.com/drive/u/0/folders/1UD5jqDtJnliBhghkhM9CVqb49ZAhr1KB'\n",
    "        #gdown.download_folder(url, remaining_ok=True)\n",
    "    \n",
    "    if not os.path.exists('./log'):\n",
    "        os.mkdir('./log')\n",
    "\n",
    "    for fix_seed in [0, 1, 42, 2021, 2022]:\n",
    "        \n",
    "        random.seed(fix_seed)\n",
    "        torch.manual_seed(fix_seed)\n",
    "        np.random.seed(fix_seed)\n",
    "    \n",
    "        for dataset in ['exchange_rate.csv']: \n",
    "            #for r in [0.0205,0.021,0.0215,0.022,0.03]: # ratio for sin.csv\n",
    "            #for r in [0.0225,0.025,0.03,0.04,0.06]: # ratio for vary.csv\n",
    "            #for r in [0.5]: # ratio for linear.csv and spikes.csv\n",
    "            for r in [0.7]: # ratio for real-world datasets\n",
    "                for pred in [96, 192, 336, 720]:\n",
    "                    for v in ['Fourier']: #Attention types: Time, Fourier, Wavelet\n",
    "                        args = Namespace(\n",
    "                        model = 'TDformer', #Transformer, MLP, TDformer\n",
    "                        activation = 'softmax',\n",
    "                        seq_len = 96, #96,\n",
    "                        label_len = 48, #48,\n",
    "                        temp = 1,\n",
    "                            \n",
    "                        pred_len = pred,\n",
    "                        version = v, \n",
    "                        data_path = dataset,\n",
    "                        ratio = r,\n",
    "                        features = 'M',\n",
    "                        target = 'OT',\n",
    "                        freq = 'h',\n",
    "                        patience = 20,\n",
    "                        enc_in = dim_dict[dataset],\n",
    "                        dec_in = dim_dict[dataset],\n",
    "                        c_out = dim_dict[dataset],\n",
    "                        adjust = False,\n",
    "                        des = '',\n",
    "                        d_model = 512,\n",
    "                        d_ff = 2048,\n",
    "                        embed = 'timeF',\n",
    "                        dropout = 0.05,\n",
    "                        output_attention = False,\n",
    "                        output_stl = False,\n",
    "                        learning_rate = 0.0001,\n",
    "                        lradj = 'type1',\n",
    "                        moving_avg = [24],\n",
    "                        gpu = 0\n",
    "                    )\n",
    "                        args.des = args.data_path[:-4] + str(args.ratio) + args.activation + 'temp' + str(args.temp) + \\\n",
    "                        args.model + args.version + str(args.pred_len) + 'seed' + str(fix_seed)\n",
    "\n",
    "                        args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "                        model = model_dict[args.model](args).float().to(args.device)\n",
    "\n",
    "                        exp = Exp_Main(args, model)  # set experiments\n",
    "                        exp.train()\n",
    "\n",
    "                        exp.test(test=1)\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('tensorboard')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57b906eaf3f7e8e516d52119501360ae3c142bd7be311060e1ed20cea4e857c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
